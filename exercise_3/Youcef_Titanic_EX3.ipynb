{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea59132a",
   "metadata": {},
   "source": [
    "# Exercice Titanic , Explications Of Parts Of the CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3a57ab",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "import email\n",
    "import email.policy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca6109",
   "metadata": {},
   "source": [
    "# Explications Of : %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a228996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enables inline plotting: Forces matplotlib visualizations to render directly in Jupyter notebooks instead of opening separate windows.\n",
    "\n",
    "#Embeds static images: Outputs plots as static PNG graphics within the notebook for easy viewing and sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0149a084",
   "metadata": {},
   "source": [
    "# Importing the functions we need from the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "from collections import Counter\n",
    "from html import unescape\n",
    "from scipy.ndimage import shift\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_curve, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b05a591",
   "metadata": {},
   "source": [
    "# Importing the DATASET FROM THE LINK : \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1aa05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")\n",
    "DOWNLOAD_URL = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a4bab",
   "metadata": {},
   "source": [
    "# Downlanding The \"titanic\" data set and verifying if \"Train.csv\" and \"test.csv Exist\" ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178df757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "def fetch_titanic_data(url=DOWNLOAD_URL, path=TITANIC_PATH):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    for filename in (\"train.csv\", \"test.csv\"):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            print(\"Downloading\", filename)\n",
    "            urllib.request.urlretrieve(url + filename, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fc7ee",
   "metadata": {},
   "source": [
    "# what (fetch_titanic_data() ) do : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f17713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates dataset directory: Checks if the TITANIC_PATH folder exists, and creates it (including parent directories) if missing.\n",
    "\n",
    "#Downloads missing files: For train.csv/test.csv, downloads from DOWNLOAD_URL only if not already present locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45164167",
   "metadata": {},
   "source": [
    "# Reading the DATA of the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98116758",
   "metadata": {},
   "source": [
    "# Loading the dataset \" train.csv \" and \" Test.csv \" into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9363e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c46d43b",
   "metadata": {},
   "source": [
    "# Print the 5 first raws of the Dataset \"Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271befd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.head())\n",
    "print(\"---\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaab741",
   "metadata": {},
   "source": [
    "# Indexing the Column of \"PassengerID\" in the Two Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe24aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.set_index(\"PassengerId\")\n",
    "test_data = test_data.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a731f5",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455a3ff-288c-4f99-8d89-459ba035e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "print(train_data.info())\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "#\n",
    "train_data[train_data[\"Sex\"]==\"female\"][\"Age\"].median()\n",
    "\n",
    "#\n",
    "print(train_data.describe())\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "#\n",
    "print(train_data[\"Survived\"].value_counts())\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "#\n",
    "print(train_data[\"Pclass\"].value_counts())\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "#\n",
    "print(train_data[\"Sex\"].value_counts())\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "#\n",
    "print(train_data[\"Embarked\"].value_counts())\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "#\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "#\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse_output=False)),\n",
    "    ])\n",
    "\n",
    "#\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])\n",
    "\n",
    "#\n",
    "X_train = preprocess_pipeline.fit_transform(\n",
    "    train_data[num_attribs + cat_attribs])\n",
    "print(X_train)\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "#\n",
    "y_train = train_data[\"Survived\"]\n",
    "\n",
    "#\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_clf.fit(X_train, y_train)\n",
    "\n",
    "#\n",
    "X_test = preprocess_pipeline.transform(test_data[num_attribs + cat_attribs])\n",
    "y_pred = forest_clf.predict(X_test)\n",
    "\n",
    "#\n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
    "print(forest_scores.mean())\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "#\n",
    "svm_clf = SVC(gamma=\"auto\")\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "print(svm_scores.mean())\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "#\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot([1]*10, svm_scores, \".\")\n",
    "plt.plot([2]*10, forest_scores, \".\")\n",
    "plt.boxplot([svm_scores, forest_scores], tick_labels=[\"SVM\", \"Random Forest\"])  # actualizado\n",
    "plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "train_data[[\"AgeBucket\", \"Survived\"]].groupby(['AgeBucket']).mean()\n",
    "print(train_data[[\"AgeBucket\", \"Survived\"]].groupby(['AgeBucket']).mean())\n",
    "print(\"---\")\n",
    "print()\n",
    "    \n",
    "#\n",
    "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "train_data[[\"RelativesOnboard\", \"Survived\"]].groupby(['RelativesOnboard']).mean()\n",
    "print(train_data[[\"RelativesOnboard\", \"Survived\"]].groupby(['RelativesOnboard']).mean())\n",
    "print(\"---\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c148b-24b7-4cfb-8d57-38fd17599220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handson-ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
