{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Predicting Hotel Room Prices\n",
    "Machine Learning in Tourism\n",
    "\n",
    "## Learning objectives:\n",
    "\n",
    "1. Apply data preprocessing techniques to prepare hotel price data for predictive modeling\n",
    "2. Implement and compare multiple regression algorithms (linear, polynomial, tree-based) for price prediction\n",
    "3. Evaluate model performance using appropriate metrics (RMSE, MAE, R²)\n",
    "4. Interpret feature importance to identify key factors affecting hotel pricing\n",
    "5. Conduct price sensitivity analysis for business decision-making in the tourism industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# For modeling\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# For model evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: DATA LOADING AND EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate synthetic hotel pricing data\n",
    "def generate_hotel_data(n_samples=10000):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create date range covering 2 years\n",
    "    start_date = datetime(2022, 1, 1)\n",
    "    dates = [start_date + timedelta(days=i) for i in range(730)]\n",
    "    \n",
    "    # Randomly select dates for our samples\n",
    "    sample_dates = np.random.choice(dates, size=n_samples)\n",
    "    \n",
    "    # Extract date features\n",
    "    month = np.array([d.month for d in sample_dates])\n",
    "    day_of_week = np.array([d.weekday() for d in sample_dates])\n",
    "    is_weekend = (day_of_week >= 5).astype(int)\n",
    "    \n",
    "    # High season: June-August (6,7,8) and December (12)\n",
    "    is_high_season = np.isin(month, [6, 7, 8, 12]).astype(int)\n",
    "    \n",
    "    # Create hotel features\n",
    "    hotel_category = np.random.choice([1, 2, 3, 4, 5], size=n_samples)  # 1-5 stars\n",
    "    distance_to_center = np.random.uniform(0, 10, size=n_samples)  # km\n",
    "    has_pool = np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3])\n",
    "    has_spa = np.random.choice([0, 1], size=n_samples, p=[0.8, 0.2])\n",
    "    has_gym = np.random.choice([0, 1], size=n_samples, p=[0.6, 0.4])\n",
    "    room_capacity = np.random.choice([1, 2, 3, 4], size=n_samples, p=[0.2, 0.5, 0.2, 0.1])\n",
    "    \n",
    "    # Booking features\n",
    "    days_in_advance = np.random.randint(1, 365, size=n_samples)\n",
    "    length_of_stay = np.random.randint(1, 15, size=n_samples)\n",
    "    nr_previous_bookings = np.random.randint(0, 10, size=n_samples)\n",
    "    \n",
    "    # Create base price influenced by various factors\n",
    "    base_price = 50 + 30 * hotel_category - 5 * distance_to_center + 20 * has_pool + 25 * has_spa + 15 * has_gym\n",
    "    \n",
    "    # Add seasonal effects\n",
    "    season_effect = 40 * is_high_season + 30 * is_weekend\n",
    "    \n",
    "    # Add booking effects: last-minute bookings are more expensive, longer stays get discounts\n",
    "    booking_effect = -0.1 * days_in_advance + 10 * np.exp(-days_in_advance/10) - 5 * length_of_stay\n",
    "    \n",
    "    # Add loyalty effects\n",
    "    loyalty_effect = -2 * nr_previous_bookings\n",
    "    \n",
    "    # Add random effects + nonlinear relationships\n",
    "    capacity_effect = 10 * (room_capacity - 1) + 5 * (room_capacity - 1)**2\n",
    "    \n",
    "    # Sum all effects\n",
    "    price = base_price + season_effect + booking_effect + loyalty_effect + capacity_effect\n",
    "    \n",
    "    # Add noise\n",
    "    price = price + np.random.normal(0, 15, n_samples)\n",
    "    \n",
    "    # Ensure price is positive and round to nearest integer\n",
    "    price = np.maximum(price, 20)\n",
    "    price = np.round(price)\n",
    "    \n",
    "    # Combine into dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'date': sample_dates,\n",
    "        'month': month,\n",
    "        'day_of_week': day_of_week,\n",
    "        'is_weekend': is_weekend,\n",
    "        'is_high_season': is_high_season,\n",
    "        'hotel_category': hotel_category,\n",
    "        'distance_to_center': distance_to_center,\n",
    "        'has_pool': has_pool,\n",
    "        'has_spa': has_spa,\n",
    "        'has_gym': has_gym,\n",
    "        'room_capacity': room_capacity,\n",
    "        'days_in_advance': days_in_advance,\n",
    "        'length_of_stay': length_of_stay,\n",
    "        'nr_previous_bookings': nr_previous_bookings,\n",
    "        'price': price\n",
    "    })\n",
    "    \n",
    "    # Add some missing values to make it more realistic\n",
    "    for col in ['has_pool', 'has_spa', 'has_gym', 'nr_previous_bookings']:\n",
    "        mask = np.random.choice([True, False], size=n_samples, p=[0.05, 0.95])\n",
    "        df.loc[mask, col] = np.nan\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Generate synthetic data\n",
    "hotel_df = generate_hotel_data(n_samples=10000)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset shape:\", hotel_df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(hotel_df.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(hotel_df.describe().T)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(hotel_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: DATA VISUALIZATION AND EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(hotel_df['price'], bins=30, kde=True)\n",
    "plt.title('Distribution of Hotel Room Prices')\n",
    "plt.xlabel('Price (€)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Price by hotel category (boxplot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='hotel_category', y='price', data=hotel_df)\n",
    "plt.title('Price by Hotel Category (Stars)')\n",
    "plt.xlabel('Hotel Category')\n",
    "plt.ylabel('Price (€)')\n",
    "plt.show()\n",
    "\n",
    "# Scatterplot: distance to center vs price, colored by hotel category\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='distance_to_center', y='price', hue='hotel_category', \n",
    "                palette='viridis', alpha=0.6, data=hotel_df)\n",
    "plt.title('Price vs Distance to Center by Hotel Category')\n",
    "plt.xlabel('Distance to City Center (km)')\n",
    "plt.ylabel('Price (€)')\n",
    "plt.legend(title='Hotel Stars')\n",
    "plt.show()\n",
    "\n",
    "# Price by month (to see seasonality)\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_avg_price = hotel_df.groupby('month')['price'].mean().reset_index()\n",
    "sns.barplot(x='month', y='price', data=monthly_avg_price)\n",
    "plt.title('Average Price by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Price (€)')\n",
    "plt.xticks(range(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                      'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.show()\n",
    "\n",
    "# Price by day of week\n",
    "plt.figure(figsize=(10, 6))\n",
    "day_avg_price = hotel_df.groupby('day_of_week')['price'].mean().reset_index()\n",
    "sns.barplot(x='day_of_week', y='price', data=day_avg_price)\n",
    "plt.title('Average Price by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Average Price (€)')\n",
    "plt.xticks(range(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "numeric_cols = hotel_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "correlation_matrix = hotel_df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numeric Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Advanced analysis: Price vs Days in Advance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='days_in_advance', y='price', data=hotel_df, alpha=0.3)\n",
    "# Add a smoothed line to see the trend\n",
    "sns.regplot(x='days_in_advance', y='price', data=hotel_df, scatter=False, \n",
    "           line_kws={\"color\": \"red\"})\n",
    "plt.title('Price vs Days in Advance')\n",
    "plt.xlabel('Days Booked in Advance')\n",
    "plt.ylabel('Price (€)')\n",
    "plt.show()\n",
    "\n",
    "# Advanced analysis: Price vs Length of Stay\n",
    "plt.figure(figsize=(12, 6))\n",
    "stay_avg_price = hotel_df.groupby('length_of_stay')['price'].mean().reset_index()\n",
    "sns.lineplot(x='length_of_stay', y='price', data=stay_avg_price, marker='o')\n",
    "plt.title('Average Price vs Length of Stay')\n",
    "plt.xlabel('Length of Stay (days)')\n",
    "plt.ylabel('Average Price (€)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = hotel_df.drop(['price', 'date'], axis=1)  # Drop price (target) and date\n",
    "y = hotel_df['price']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = ['month', 'day_of_week', 'hotel_category', 'room_capacity']\n",
    "numerical_features = ['distance_to_center', 'days_in_advance', 'length_of_stay', \n",
    "                     'nr_previous_bookings']\n",
    "binary_features = ['is_weekend', 'is_high_season', 'has_pool', 'has_spa', 'has_gym']\n",
    "\n",
    "# Create preprocessing pipeline for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create preprocessing pipeline for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Create preprocessing pipeline for binary features\n",
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Combine all transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('bin', binary_transformer, binary_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing to training data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Processed training data shape:\", X_train_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the processed feature names\n",
    "# Get feature names after preprocessing\n",
    "# Note: The feature names for the categorical features are generated by OneHotEncoder\n",
    "# and need to be extracted from the pipeline\n",
    "feature_names = (\n",
    "    numerical_features + \n",
    "    list(preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_features)) +\n",
    "    binary_features\n",
    ")\n",
    "print(\"Processed feature names:\", feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4: BASELINE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Return all metrics\n",
    "    return {\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2\n",
    "    }\n",
    "\n",
    "# Create dictionary to store all model results\n",
    "model_results = {}\n",
    "\n",
    "# 1. Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "model_results['Linear Regression'] = evaluate_model(\n",
    "    lr_model, X_train_processed, X_test_processed, y_train, y_test\n",
    ")\n",
    "\n",
    "# 2. Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "model_results['Ridge Regression'] = evaluate_model(\n",
    "    ridge_model, X_train_processed, X_test_processed, y_train, y_test\n",
    ")\n",
    "\n",
    "# 3. Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "model_results['Lasso Regression'] = evaluate_model(\n",
    "    lasso_model, X_train_processed, X_test_processed, y_train, y_test\n",
    ")\n",
    "\n",
    "# 4. ElasticNet\n",
    "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "model_results['ElasticNet'] = evaluate_model(\n",
    "    elasticnet_model, X_train_processed, X_test_processed, y_train, y_test\n",
    ")\n",
    "\n",
    "# Display results in a dataframe\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "results_df = results_df[['train_rmse', 'test_rmse', 'train_mae', 'test_mae', 'train_r2', 'test_r2']]\n",
    "results_df = results_df.sort_values('test_rmse')\n",
    "print(\"\\nLinear Model Performance:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 5: POLYNOMIAL REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a polynomial features pipeline\n",
    "polynomial_preprocessor = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True))\n",
    "])\n",
    "\n",
    "# Apply preprocessing to training data\n",
    "X_train_poly = polynomial_preprocessor.fit_transform(X_train)\n",
    "X_test_poly = polynomial_preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Polynomial training data shape:\", X_train_poly.shape)\n",
    "\n",
    "# Ridge regression with polynomial features (to avoid overfitting)\n",
    "poly_ridge_model = Ridge(alpha=10.0)\n",
    "model_results['Polynomial Ridge'] = evaluate_model(\n",
    "    poly_ridge_model, X_train_poly, X_test_poly, y_train, y_test\n",
    ")\n",
    "\n",
    "# Update results dataframe\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "results_df = results_df[['train_rmse', 'test_rmse', 'train_mae', 'test_mae', 'train_r2', 'test_r2']]\n",
    "results_df = results_df.sort_values('test_rmse')\n",
    "print(\"\\nLinear and Polynomial Model Performance:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 6: TREE-BASED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Decision Tree\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "model_results['Decision Tree'] = evaluate_model(\n",
    "    dt_model, X_train_processed, X_test_processed, y_train, y_test\n",
    ")\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "model_results['Random Forest'] = evaluate_model(\n",
    "    rf_model, X_train_processed, X_test_processed, y_train, y_test\n",
    ")\n",
    "\n",
    "# 3. Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "model_results['Gradient Boosting'] = evaluate_model(\n",
    "    gb_model, X_train_processed, X_test_processed, y_train, y_test\n",
    ")\n",
    "\n",
    "# 4. XGBoost\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "model_results['XGBoost'] = evaluate_model(\n",
    "    xgb_model, X_train_processed, X_test_processed, y_train, y_test\n",
    ")\n",
    "\n",
    "# Update results dataframe\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "results_df = results_df[['train_rmse', 'test_rmse', 'train_mae', 'test_mae', 'train_r2', 'test_r2']]\n",
    "results_df = results_df.sort_values('test_rmse')\n",
    "print(\"\\nAll Models Performance:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 7: HYPERPARAMETER TUNING\n",
    "We adjust Random Forest as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for ElasticNet\n",
    "param_grid_elasticnet = {\n",
    "    'elasticnet__alpha': [0.01, 0.1, 1.0, 10.0],  # Regularization strength\n",
    "    'elasticnet__l1_ratio': [0.1, 0.5, 0.7, 0.9]  # Balance between L1 and L2 regularization\n",
    "}\n",
    "\n",
    "# Create an ElasticNet model\n",
    "elasticnet = ElasticNet(max_iter=10000)\n",
    "\n",
    "# Create a pipeline with polynomial preprocessing and ElasticNet\n",
    "elasticnet_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', polynomial_preprocessor),\n",
    "    ('elasticnet', elasticnet)\n",
    "])\n",
    "\n",
    "# Create GridSearchCV for ElasticNet\n",
    "grid_search_elasticnet = GridSearchCV(\n",
    "    estimator=elasticnet_pipeline,\n",
    "    param_grid=param_grid_elasticnet,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_elasticnet.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"\\nBest parameters for ElasticNet:\", grid_search_elasticnet.best_params_)\n",
    "print(\"Best RMSE for ElasticNet:\", -grid_search_elasticnet.best_score_)\n",
    "\n",
    "# Create the best ElasticNet model with optimal parameters\n",
    "best_elasticnet_model = grid_search_elasticnet.best_estimator_\n",
    "\n",
    "# Evaluate the best ElasticNet model\n",
    "model_results['ElasticNet (Tuned)'] = evaluate_model(\n",
    "    best_elasticnet_model.named_steps['elasticnet'], \n",
    "    X_train_poly, \n",
    "    X_test_poly, \n",
    "    y_train, \n",
    "    y_test\n",
    ")\n",
    "\n",
    "# Update results dataframe\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "results_df = results_df[['train_rmse', 'test_rmse', 'train_mae', 'test_mae', 'train_r2', 'test_r2']]\n",
    "results_df = results_df.sort_values('test_rmse')\n",
    "print(\"\\nUpdated Model Performance:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest hyperparameter tuning with GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [1.0, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create GridSearchCV for Random Forest\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_rf.fit(X_train_processed, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"\\nBest parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "print(\"Best RMSE for Random Forest:\", -grid_search_rf.best_score_)\n",
    "\n",
    "# Create best model with optimal parameters\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "model_results['Random Forest (Tuned)'] = evaluate_model(\n",
    "    best_rf_model, X_train_processed, X_test_processed, y_train, y_test\n",
    ")\n",
    "\n",
    "# Update results dataframe\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "results_df = results_df[['train_rmse', 'test_rmse', 'train_mae', 'test_mae', 'train_r2', 'test_r2']]\n",
    "results_df = results_df.sort_values('test_rmse')\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 8: FEATURE IMPORTANCE AND MODEL INTERPRETATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Random Forest model\n",
    "importances = best_rf_model.feature_importances_\n",
    "feature_importances = pd.DataFrame(importances, index=feature_names, columns=['importance'])\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=feature_importances['importance'], y=feature_importances.index)\n",
    "plt.title('Feature Importances from Random Forest Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 9: PREDICTIONS ON NEW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to make price predictions for new hotels\n",
    "def predict_price(model, preprocessor, hotel_data):\n",
    "    # Preprocess the data\n",
    "    hotel_data_processed = preprocessor.transform(hotel_data)\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_price = model.predict(hotel_data_processed)\n",
    "    \n",
    "    return predicted_price[0]\n",
    "\n",
    "# Example: Create a new hotel data point\n",
    "new_hotel = pd.DataFrame({\n",
    "    'month': [7],  # July\n",
    "    'day_of_week': [5],  # Saturday\n",
    "    'is_weekend': [1],\n",
    "    'is_high_season': [1],\n",
    "    'hotel_category': [4],  # 4-star hotel\n",
    "    'distance_to_center': [1.5],  # 1.5 km from center\n",
    "    'has_pool': [1],\n",
    "    'has_spa': [1],\n",
    "    'has_gym': [1],\n",
    "    'room_capacity': [2],  # Double room\n",
    "    'days_in_advance': [30],  # Booked 30 days in advance\n",
    "    'length_of_stay': [7],  # 7-day stay\n",
    "    'nr_previous_bookings': [2]  # Customer with 2 previous bookings\n",
    "})\n",
    "\n",
    "# Predict price for the new hotel\n",
    "predicted_price = predict_price(best_elasticnet_model.named_steps['elasticnet'], polynomial_preprocessor, new_hotel)\n",
    "print(f\"\\nPredicted price for the new hotel: €{predicted_price:.2f}\")\n",
    "\n",
    "# Create a few more examples with different parameters\n",
    "example_hotels = pd.DataFrame({\n",
    "    'month': [7, 7, 1, 12],  # July, July, January, December\n",
    "    'day_of_week': [5, 1, 3, 6],  # Saturday, Tuesday, Thursday, Sunday\n",
    "    'is_weekend': [1, 0, 0, 1],\n",
    "    'is_high_season': [1, 1, 0, 1],\n",
    "    'hotel_category': [4, 3, 5, 5],  \n",
    "    'distance_to_center': [1.5, 4.0, 0.5, 2.0],\n",
    "    'has_pool': [1, 0, 1, 1],\n",
    "    'has_spa': [1, 0, 1, 1],\n",
    "    'has_gym': [1, 1, 1, 1],\n",
    "    'room_capacity': [2, 2, 1, 3],\n",
    "    'days_in_advance': [30, 10, 90, 180],\n",
    "    'length_of_stay': [7, 3, 2, 10],\n",
    "    'nr_previous_bookings': [2, 0, 5, 1]\n",
    "})\n",
    "\n",
    "# Preprocess the examples\n",
    "examples_processed = preprocessor.transform(example_hotels)\n",
    "\n",
    "# Make predictions\n",
    "predicted_prices = best_rf_model.predict(examples_processed)\n",
    "\n",
    "# Add predictions to the example dataframe\n",
    "example_hotels['predicted_price'] = predicted_prices.round(2)\n",
    "\n",
    "# Display the examples with predictions\n",
    "print(\"\\nPredicted prices for different hotels:\")\n",
    "display(example_hotels[['hotel_category', 'distance_to_center', 'is_weekend', \n",
    "                      'is_high_season', 'days_in_advance', 'length_of_stay', \n",
    "                      'predicted_price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 10: SCENARIO ANALYSIS\n",
    "### With RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to analyze price sensitivity to a specific feature\n",
    "def analyze_price_sensitivity(model, preprocessor, base_hotel, feature, range_values):\n",
    "    # Create multiple versions of the hotel with different values of the feature\n",
    "    hotels = pd.concat([base_hotel] * len(range_values), ignore_index=True)\n",
    "    hotels[feature] = range_values\n",
    "    \n",
    "    # Preprocess the hotels\n",
    "    hotels_processed = preprocessor.transform(hotels)\n",
    "    \n",
    "    # Make predictions\n",
    "    predicted_prices = model.predict(hotels_processed)\n",
    "    \n",
    "    return predicted_prices\n",
    "\n",
    "# Base hotel for sensitivity analysis\n",
    "base_hotel = pd.DataFrame({\n",
    "    'month': [7],  # July\n",
    "    'day_of_week': [3],  # Thursday\n",
    "    'is_weekend': [0],\n",
    "    'is_high_season': [1],\n",
    "    'hotel_category': [3],  # 3-star hotel\n",
    "    'distance_to_center': [2.0],  # 2 km from center\n",
    "    'has_pool': [1],\n",
    "    'has_spa': [0],\n",
    "    'has_gym': [1],\n",
    "    'room_capacity': [2],  # Double room\n",
    "    'days_in_advance': [30],  # Booked 30 days in advance\n",
    "    'length_of_stay': [4],  # 4-day stay\n",
    "    'nr_previous_bookings': [1]  # Customer with 1 previous booking\n",
    "})\n",
    "\n",
    "# Analyze sensitivity to days in advance\n",
    "days_range = range(1, 180, 7)  # 1 to 180 days in 7-day increments\n",
    "prices_by_days = analyze_price_sensitivity(\n",
    "    best_rf_model, preprocessor, base_hotel, 'days_in_advance', days_range\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(days_range, prices_by_days, marker='o')\n",
    "plt.title('Price Sensitivity to Booking Days in Advance')\n",
    "plt.xlabel('Days in Advance')\n",
    "plt.ylabel('Predicted Price (€)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Analyze sensitivity to hotel category\n",
    "category_range = [1, 2, 3, 4, 5]\n",
    "prices_by_category = analyze_price_sensitivity(\n",
    "    best_rf_model, preprocessor, base_hotel, 'hotel_category', category_range\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(category_range, prices_by_category)\n",
    "plt.title('Price Sensitivity to Hotel Category')\n",
    "plt.xlabel('Hotel Category (Stars)')\n",
    "plt.ylabel('Predicted Price (€)')\n",
    "plt.xticks(category_range)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Analyze sensitivity to length of stay\n",
    "stay_range = range(1, 15)\n",
    "prices_by_stay = analyze_price_sensitivity(\n",
    "    best_rf_model, preprocessor, base_hotel, 'length_of_stay', stay_range\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(stay_range, prices_by_stay, marker='o')\n",
    "plt.title('Price Sensitivity to Length of Stay')\n",
    "plt.xlabel('Length of Stay (days)')\n",
    "plt.ylabel('Predicted Price (€)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With polynomial ElasticNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to analyze price sensitivity to a specific feature\n",
    "def analyze_price_sensitivity(model, preprocessor, base_hotel, feature, range_values):\n",
    "    # Create multiple versions of the hotel with different values of the feature\n",
    "    hotels = pd.concat([base_hotel] * len(range_values), ignore_index=True)\n",
    "    hotels[feature] = range_values\n",
    "    \n",
    "    # Preprocess the hotels\n",
    "    hotels_processed = preprocessor.transform(hotels)\n",
    "    \n",
    "    # Make predictions\n",
    "    predicted_prices = model.predict(hotels_processed)\n",
    "    \n",
    "    return predicted_prices\n",
    "\n",
    "# Base hotel for sensitivity analysis\n",
    "base_hotel = pd.DataFrame({\n",
    "    'month': [7],  # July\n",
    "    'day_of_week': [3],  # Thursday\n",
    "    'is_weekend': [0],\n",
    "    'is_high_season': [1],\n",
    "    'hotel_category': [3],  # 3-star hotel\n",
    "    'distance_to_center': [2.0],  # 2 km from center\n",
    "    'has_pool': [1],\n",
    "    'has_spa': [0],\n",
    "    'has_gym': [1],\n",
    "    'room_capacity': [2],  # Double room\n",
    "    'days_in_advance': [30],  # Booked 30 days in advance\n",
    "    'length_of_stay': [4],  # 4-day stay\n",
    "    'nr_previous_bookings': [1]  # Customer with 1 previous booking\n",
    "})\n",
    "\n",
    "# Analyze sensitivity to days in advance\n",
    "days_range = range(1, 180, 7)  # 1 to 180 days in 7-day increments\n",
    "prices_by_days = analyze_price_sensitivity(\n",
    "    best_elasticnet_model.named_steps['elasticnet'], polynomial_preprocessor, base_hotel, 'days_in_advance', days_range\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(days_range, prices_by_days, marker='o')\n",
    "plt.title('Price Sensitivity to Booking Days in Advance')\n",
    "plt.xlabel('Days in Advance')\n",
    "plt.ylabel('Predicted Price (€)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Analyze sensitivity to hotel category\n",
    "category_range = [1, 2, 3, 4, 5]\n",
    "prices_by_category = analyze_price_sensitivity(\n",
    "    best_rf_model, preprocessor, base_hotel, 'hotel_category', category_range\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(category_range, prices_by_category)\n",
    "plt.title('Price Sensitivity to Hotel Category')\n",
    "plt.xlabel('Hotel Category (Stars)')\n",
    "plt.ylabel('Predicted Price (€)')\n",
    "plt.xticks(category_range)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Analyze sensitivity to length of stay\n",
    "stay_range = range(1, 15)\n",
    "prices_by_stay = analyze_price_sensitivity(\n",
    "    best_rf_model, preprocessor, base_hotel, 'length_of_stay', stay_range\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(stay_range, prices_by_stay, marker='o')\n",
    "plt.title('Price Sensitivity to Length of Stay')\n",
    "plt.xlabel('Length of Stay (days)')\n",
    "plt.ylabel('Predicted Price (€)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 11: CONCLUSION AND KEY FINDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the results by test RMSE\n",
    "results_df = results_df.sort_values('test_rmse')\n",
    "# Display the best model performance\n",
    "print(\"\\nBest model performance:\")\n",
    "print(\"Best model performance:\", results_df.iloc[0].name, \n",
    "      f\"with RMSE: {results_df.iloc[0]['test_rmse']:.2f} and R²: {results_df.iloc[0]['test_r2']:.4f}\")\n",
    "print(\"Second best model performance:\", results_df.iloc[1].name,\n",
    "      f\"with RMSE: {results_df.iloc[1]['test_rmse']:.2f} and R²: {results_df.iloc[1]['test_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----- KEY FINDINGS -----\n",
    "1. Most important factors affecting hotel prices (based on feature importance):\n",
    "   - Hotel category (star rating)\n",
    "   - Seasonality (high season vs. low season)\n",
    "   - Weekend vs. weekday\n",
    "   - Distance to city center\n",
    "2. Pricing insights:\n",
    "   - Booking far in advance can save money\n",
    "   - Longer stays generally get better per-night rates\n",
    "   - High season periods show significant price increases\n",
    "   - Each star category represents a substantial price jump\n",
    "\n",
    "----- BUSINESS RECOMMENDATIONS -----\n",
    "1. For hotels:\n",
    "   - Adjust pricing strategies based on demand patterns and advance booking curve\n",
    "   - Implement dynamic pricing for weekends and high seasons\n",
    "   - Consider loyalty discounts for repeat customers\n",
    "2. For customers:\n",
    "   - Book well in advance for high season travel\n",
    "   - Consider longer stays for better per-night rates\n",
    "   - Weigh hotel category against location (distance to center)\n",
    "3. For online travel agencies:\n",
    "   - Highlight potential savings for advance bookings\n",
    "   - Create personalized pricing recommendations\n",
    "   - Implement price prediction tools for customers\n",
    "\n",
    "This analysis demonstrates how regression techniques can be effectively applied\n",
    "to predict hotel room prices and generate actionable insights for the tourism industry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
