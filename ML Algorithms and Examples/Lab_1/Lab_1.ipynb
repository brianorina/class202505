{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Data Preprocessing for Hotel Booking Cancellations\n",
    "Machine Learning in Tourism - Lab 1\n",
    "\n",
    "## Learning objectives:\n",
    "\n",
    "1. Preprocess and clean hotel booking data, handling missing values and data conversions\n",
    "2. Create meaningful derived variables through feature engineering\n",
    "3. Apply exploratory data analysis with visualization tools\n",
    "4. Build a machine learning pipeline for numerical and categorical features\n",
    "5. Evaluate a booking cancellation prediction model and interpret feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this lab, we'll use the Hotel Booking Demand dataset\n",
    "# The dataset contains booking information for a city hotel and a resort hotel\n",
    "# including information such as when the booking was made, length of stay, \n",
    "# number of adults, children, and/or babies, and many other features\n",
    "\n",
    "# You would typically download this dataset or access it from your local system\n",
    "# For the purpose of this lab, we'll use a direct URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\"\n",
    "try:\n",
    "    # Try to load the data from the URL\n",
    "    df = pd.read_csv(url)\n",
    "    print(f\"Dataset loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the dataset: {e}\")\n",
    "    print(\"Using backup approach with sample data...\")\n",
    "    \n",
    "    # If the URL fails, we'll create a synthetic dataset for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_samples = 5000\n",
    "    \n",
    "    # Create synthetic data that mimics hotel booking features\n",
    "    df = pd.DataFrame({\n",
    "        'hotel': np.random.choice(['Resort Hotel', 'City Hotel'], n_samples),\n",
    "        'is_canceled': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),\n",
    "        'lead_time': np.random.randint(0, 365, n_samples),\n",
    "        'arrival_date_year': np.random.choice([2018, 2019], n_samples),\n",
    "        'arrival_date_month': np.random.choice(['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                                               'July', 'August', 'September', 'October', 'November', 'December'], n_samples),\n",
    "        'arrival_date_week_number': np.random.randint(1, 53, n_samples),\n",
    "        'arrival_date_day_of_month': np.random.randint(1, 31, n_samples),\n",
    "        'stays_in_weekend_nights': np.random.randint(0, 5, n_samples),\n",
    "        'stays_in_week_nights': np.random.randint(0, 15, n_samples),\n",
    "        'adults': np.random.randint(1, 4, n_samples),\n",
    "        'children': np.random.choice([0, 1, 2], n_samples, p=[0.6, 0.3, 0.1]),\n",
    "        'babies': np.random.choice([0, 1], n_samples, p=[0.9, 0.1]),\n",
    "        'meal': np.random.choice(['BB', 'HB', 'FB', 'SC'], n_samples),\n",
    "        'country': np.random.choice(['PRT', 'GBR', 'FRA', 'ESP', 'DEU'], n_samples),\n",
    "        'market_segment': np.random.choice(['Online TA', 'Offline TA', 'Direct', 'Corporate', 'Groups'], n_samples),\n",
    "        'distribution_channel': np.random.choice(['TA/TO', 'Direct', 'Corporate'], n_samples),\n",
    "        'is_repeated_guest': np.random.choice([0, 1], n_samples, p=[0.9, 0.1]),\n",
    "        'previous_cancellations': np.random.choice([0, 1, 2], n_samples, p=[0.8, 0.15, 0.05]),\n",
    "        'previous_bookings_not_canceled': np.random.choice([0, 1, 2, 3], n_samples, p=[0.7, 0.2, 0.05, 0.05]),\n",
    "        'reserved_room_type': np.random.choice(['A', 'B', 'C', 'D', 'E'], n_samples),\n",
    "        'assigned_room_type': np.random.choice(['A', 'B', 'C', 'D', 'E'], n_samples),\n",
    "        'booking_changes': np.random.choice([0, 1, 2, 3], n_samples, p=[0.7, 0.2, 0.05, 0.05]),\n",
    "        'deposit_type': np.random.choice(['No Deposit', 'Refundable', 'Non Refund'], n_samples, p=[0.8, 0.1, 0.1]),\n",
    "        'days_in_waiting_list': np.random.choice([0, 1, 2, 3, 5, 10], n_samples, p=[0.7, 0.1, 0.05, 0.05, 0.05, 0.05]),\n",
    "        'customer_type': np.random.choice(['Transient', 'Contract', 'Transient-Party', 'Group'], n_samples),\n",
    "        'adr': np.random.uniform(50, 300, n_samples),  # Average Daily Rate\n",
    "        'required_car_parking_spaces': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),\n",
    "        'total_of_special_requests': np.random.choice([0, 1, 2, 3], n_samples, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "        'reservation_status': np.random.choice(['Check-Out', 'Canceled', 'No-Show'], n_samples, p=[0.6, 0.35, 0.05]),\n",
    "    })\n",
    "    \n",
    "    # Introduce some missing values to demonstrate handling\n",
    "    for col in ['children', 'country', 'agent', 'adr']:\n",
    "        mask = np.random.choice([True, False], size=df.shape[0], p=[0.05, 0.95])\n",
    "        df.loc[mask, col] = np.nan\n",
    "    \n",
    "    print(f\"Synthetic dataset created with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"\\nDataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of the numerical columns\n",
    "print(\"\\nStatistical summary:\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing values count:\")\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target variable (is_canceled)\n",
    "print(\"\\nDistribution of booking cancellations:\")\n",
    "cancellation_counts = df['is_canceled'].value_counts(normalize=True) * 100\n",
    "print(cancellation_counts)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='is_canceled', data=df, palette='viridis', hue='is_canceled', legend=False)\n",
    "plt.title('Distribution of Booking Cancellations')\n",
    "plt.xlabel('Canceled (1) vs. Not Canceled (0)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add percentages on top of the bars\n",
    "total = len(df)\n",
    "for p in ax.patches:\n",
    "    percentage = f'{100 * p.get_height() / total:.1f}%'\n",
    "    x = p.get_x() + p.get_width() / 2\n",
    "    y = p.get_height()\n",
    "    ax.annotate(percentage, (x, y), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe for preprocessing\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Check datatypes and convert if necessary\n",
    "print(\"\\nData types before conversion:\")\n",
    "display(df_clean.dtypes)\n",
    "\n",
    "# Convert 'children' column to numeric if it's not already\n",
    "if df_clean['children'].dtype == 'object':\n",
    "    df_clean['children'] = pd.to_numeric(df_clean['children'], errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "print(\"\\nHandling missing values...\")\n",
    "\n",
    "# For numerical columns, impute with median\n",
    "numerical_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in numerical_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        median_value = df_clean[col].median()\n",
    "        df_clean[col].fillna(median_value, inplace=True)\n",
    "        print(f\"Imputed {col} with median value: {median_value}\")\n",
    "\n",
    "# For categorical columns, impute with mode\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        mode_value = df_clean[col].mode()[0]\n",
    "        df_clean[col].fillna(mode_value, inplace=True)\n",
    "        print(f\"Imputed {col} with mode value: {mode_value}\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "missing_after = df_clean.isnull().sum().sum()\n",
    "print(f\"\\nTotal missing values after imputation: {missing_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dtypes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Create a total nights feature\n",
    "df_clean['total_nights'] = df_clean['stays_in_weekend_nights'] + df_clean['stays_in_week_nights']\n",
    "print(\"Created 'total_nights' feature\")\n",
    "\n",
    "# 4.2 Create a total guests feature\n",
    "df_clean['total_guests'] = df_clean['adults'] + df_clean['children'] + df_clean['babies']\n",
    "print(\"Created 'total_guests' feature\")\n",
    "\n",
    "# 4.3 Extract season from arrival_date_month\n",
    "def get_season(month):\n",
    "    if month in ['December', 'January', 'February']:\n",
    "        return 'Winter'\n",
    "    elif month in ['March', 'April', 'May']:\n",
    "        return 'Spring'\n",
    "    elif month in ['June', 'July', 'August']:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "df_clean['season'] = df_clean['arrival_date_month'].apply(get_season)\n",
    "print(\"Created 'season' feature based on arrival month\")\n",
    "\n",
    "# 4.4 Create a binary feature for high or low booking lead time\n",
    "median_lead_time = df_clean['lead_time'].median()\n",
    "df_clean['high_lead_time'] = (df_clean['lead_time'] > median_lead_time).astype(int)\n",
    "print(f\"Created 'high_lead_time' feature (1 if lead time > {median_lead_time} days)\")\n",
    "\n",
    "# 4.5 Create price per person\n",
    "df_clean['price_per_person'] = df_clean['adr'] / df_clean['total_guests'].replace(0, 1)  # Avoid division by zero\n",
    "print(\"Created 'price_per_person' feature\")\n",
    "\n",
    "# 4.6 Check if the assigned room type matches the reserved room type\n",
    "df_clean['got_requested_room'] = (df_clean['reserved_room_type'] == df_clean['assigned_room_type']).astype(int)\n",
    "print(\"Created 'got_requested_room' feature\")\n",
    "\n",
    "# 4.7 Create weekend vs. weekday stay ratio\n",
    "df_clean['weekend_ratio'] = df_clean['stays_in_weekend_nights'] / df_clean['total_nights'].replace(0, 1)\n",
    "print(\"Created 'weekend_ratio' feature\")\n",
    "\n",
    "# Display the new features\n",
    "print(\"\\nDataset with new features:\")\n",
    "display(df_clean[['total_nights', 'total_guests', 'season', 'high_lead_time', \n",
    "                'price_per_person', 'got_requested_room', 'weekend_ratio']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Cancellation rate by hotel type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='hotel', hue='is_canceled', data=df_clean, palette='viridis')\n",
    "plt.title('Cancellation Rate by Hotel Type')\n",
    "plt.xlabel('Hotel Type')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Canceled', labels=['No', 'Yes'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.2 Cancellation rate by season\n",
    "plt.figure(figsize=(12, 6))\n",
    "cancellation_by_season = pd.crosstab(df_clean['season'], df_clean['is_canceled'], normalize='index') * 100\n",
    "cancellation_by_season.plot(kind='bar', stacked=True, colormap='viridis', figsize=(10, 6))\n",
    "plt.title('Cancellation Rate by Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend(title='Canceled', labels=['No', 'Yes'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.3 Lead time distribution for canceled vs. not canceled bookings\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df_clean, x='lead_time', hue='is_canceled', bins=30, kde=True, element='step')\n",
    "plt.title('Lead Time Distribution by Cancellation Status')\n",
    "plt.xlabel('Lead Time (days)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Canceled', labels=['No', 'Yes'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.4 Average Daily Rate (ADR) by hotel type and cancellation status\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='hotel', y='adr', hue='is_canceled', data=df_clean, palette='viridis')\n",
    "plt.title('ADR Distribution by Hotel Type and Cancellation Status')\n",
    "plt.xlabel('Hotel Type')\n",
    "plt.ylabel('Average Daily Rate (ADR)')\n",
    "plt.legend(title='Canceled', labels=['No', 'Yes'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.5 Correlation matrix of numerical features\n",
    "numerical_features = ['lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights', \n",
    "                     'adults', 'children', 'babies', 'is_repeated_guest',\n",
    "                     'previous_cancellations', 'previous_bookings_not_canceled',\n",
    "                     'booking_changes', 'days_in_waiting_list', 'adr',\n",
    "                     'required_car_parking_spaces', 'total_of_special_requests',\n",
    "                     'total_nights', 'total_guests', 'high_lead_time', \n",
    "                     'price_per_person', 'got_requested_room', 'weekend_ratio']\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "numerical_features = [col for col in numerical_features if col in df_clean.columns]\n",
    "\n",
    "correlation_matrix = df_clean[numerical_features].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            linewidths=0.5, square=True)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.6 Cancellation rate by deposit type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='deposit_type', hue='is_canceled', data=df_clean, palette='viridis')\n",
    "plt.title('Cancellation Rate by Deposit Type')\n",
    "plt.xlabel('Deposit Type')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Canceled', labels=['No', 'Yes'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.7 Cancellation rate by market segment\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='market_segment', hue='is_canceled', data=df_clean, palette='viridis')\n",
    "plt.title('Cancellation Rate by Market Segment')\n",
    "plt.xlabel('Market Segment')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Canceled', labels=['No', 'Yes'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5.4 Average Daily Rate (ADR) by hotel type and cancellation status (ZOOM)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='hotel', y='adr', hue='is_canceled', data=df_clean[df_clean['adr']<1000], palette='viridis')\n",
    "plt.title('ADR Distribution by Hotel Type and Cancellation Status (ZOOM)')\n",
    "plt.xlabel('Hotel Type')\n",
    "plt.ylabel('Average Daily Rate (ADR)')\n",
    "plt.legend(title='Canceled', labels=['No', 'Yes'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. FEATURE SELECTION AND PREPROCESSING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Select features based on business knowledge and correlation analysis\n",
    "selected_features = [\n",
    "    'hotel', 'lead_time', 'arrival_date_month', 'arrival_date_week_number',\n",
    "    'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children',\n",
    "    'meal', 'market_segment', 'distribution_channel', 'is_repeated_guest',\n",
    "    'previous_cancellations', 'previous_bookings_not_canceled',\n",
    "    'reserved_room_type', 'assigned_room_type', 'booking_changes',\n",
    "    'deposit_type', 'days_in_waiting_list', 'customer_type', 'adr',\n",
    "    'required_car_parking_spaces', 'total_of_special_requests',\n",
    "    'total_nights', 'season', 'high_lead_time', 'price_per_person',\n",
    "    'got_requested_room', 'weekend_ratio'\n",
    "]\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "selected_features = [col for col in selected_features if col in df_clean.columns]\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = df_clean[selected_features]\n",
    "y = df_clean['is_canceled']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# 6.2 Identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"\\nNumerical features ({len(numerical_features)}): {numerical_features}\")\n",
    "\n",
    "# 6.3 Create preprocessing pipelines\n",
    "# Numerical pipeline: imputation + scaling\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline: imputation + one-hot encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Column transformer to apply the appropriate preprocessing to each column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# 6.4 Fit the preprocessing pipeline to the training data\n",
    "print(\"\\nFitting the preprocessing pipeline...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Processed training data shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed test data shape: {X_test_processed.shape}\")\n",
    "\n",
    "# Get the feature names after one-hot encoding\n",
    "cat_feature_names = []\n",
    "for i, col in enumerate(categorical_features):\n",
    "    # Get the categories for this feature\n",
    "    categories = preprocessor.transformers_[1][1].named_steps['onehot'].categories_[i]\n",
    "    # Create feature names by combining column name with category\n",
    "    for category in categories:\n",
    "        cat_feature_names.append(f\"{col}_{category}\")\n",
    "\n",
    "# Combine with numerical feature names\n",
    "processed_feature_names = numerical_features + cat_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Feature importance using a simple model (Random Forest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a simple Random Forest model\n",
    "print(\"\\nTraining a Random Forest model for feature importance...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "if len(processed_feature_names) == X_train_processed.shape[1]:\n",
    "    importances = rf_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': processed_feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Display top 20 features\n",
    "    print(\"\\nTop 20 most important features:\")\n",
    "    print(feature_importance.head(20))\n",
    "    \n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(20), palette='viridis', hue='Feature', legend=False)\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nWarning: Feature names length does not match processed data width.\")\n",
    "    print(f\"Feature names length: {len(processed_feature_names)}\")\n",
    "    print(f\"Processed data width: {X_train_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test_processed)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SUMMARY AND CONCLUSIONS\n",
    "In this lab, we have:\n",
    "1. Loaded and explored hotel booking data\n",
    "2. Cleaned the data by handling missing values\n",
    "3. Engineered new features to improve predictive power\n",
    "4. Performed exploratory data analysis to understand relationships\n",
    "5. Created a preprocessing pipeline for both numerical and categorical features\n",
    "6. Built a simple Random Forest model to analyze feature importance\n",
    "7. Evaluated the model's performance in predicting booking cancellations\n",
    "\n",
    "Key insights:\n",
    "- Lead time is one of the most important features for predicting cancellations\n",
    "- Deposit type significantly affects cancellation rates\n",
    "- Price and room type assignment also play important roles\n",
    "- Seasonal patterns exist in booking cancellations\n",
    "\n",
    "Next steps:\n",
    "- Further explore interaction effects between features\n",
    "- Try more advanced models and compare performance\n",
    "- Implement hyperparameter tuning to optimize model performance\n",
    "- Consider business context when interpreting and applying models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
